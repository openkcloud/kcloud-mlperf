## kcloud-mlperf â€” ì¿ ë²„ë„¤í‹°ìŠ¤ LLM ë²¤ì¹˜ë§ˆí¬ (Llama 3.1 8B)

**ë§ˆìŠ¤í„°/ì›Œì»¤ IPë§Œ ì„¤ì •í•˜ë©´ ë°”ë¡œ ì‹¤í–‰ë˜ëŠ”** bare-metal K8s ë²¤ì¹˜ë§ˆí¬ ëª¨ìŒì…ë‹ˆë‹¤.

| ë²¤ì¹˜ë§ˆí¬ | ì„¤ëª… | êµ¬í˜„ |
|---|---|---|
| **MLPerf Inference** | CNN/DailyMail ìš”ì•½ â†’ ROUGE | **MLCommons ê³µì‹ LoadGen** |
| **MMLU-Pro** | 5-shot CoT í‰ê°€ â†’ ì •í™•ë„ | TIGER-Lab ê³µì‹ |
| **LLM Inference** | vLLM ì²˜ë¦¬ëŸ‰ í…ŒìŠ¤íŠ¸ | vLLM ë°±ì—”ë“œ |

> **ê¶Œì¥:** í•­ìƒ `--smoke`(10ìƒ˜í”Œ) ë¨¼ì € í†µê³¼ â†’ í’€ ë°ì´í„° ì‹¤í–‰

---

## âœ… ì²˜ìŒ ì‚¬ìš©ì 3ë‹¨ê³„ (ë°”ë¡œ ì‹¤í–‰)

### 0) ì¤€ë¹„ë¬¼
- Ubuntu 20.04/22.04 ë¨¸ì‹  2ëŒ€ ì´ìƒ (ë§ˆìŠ¤í„° 1 + GPU ì›Œì»¤ 1+)
- ì›Œì»¤ ë…¸ë“œì— NVIDIA ë“œë¼ì´ë²„ ì„¤ì¹˜
- HuggingFace í† í° (Llama 3.1 ë¼ì´ì„ ìŠ¤ ìŠ¹ì¸ í•„ìš”)

### 1) ë ˆí¬ ë°›ê¸° + ì„¤ì • íŒŒì¼ ì‘ì„±
```bash
git clone --recursive https://github.com/openkcloud/kcloud-mlperf.git
cd kcloud-mlperf

cp config/cluster.env config/cluster.env.local
nano config/cluster.env.local
```

`config/cluster.env.local` ì˜ˆì‹œ:
```bash
MASTER_IP="129.254.202.181"
WORKER_IP="129.254.202.129"
WORKER_USER="kcloud"
WORKER_SSH_PORT="22"   # í•„ìš” ì‹œ ìˆ˜ì •
HF_TOKEN="hf_..."
```

### 2) í´ëŸ¬ìŠ¤í„° ì„¤ì¹˜ (ë§ˆìŠ¤í„° â†’ ì›Œì»¤)
**ë§ˆìŠ¤í„°ì—ì„œ ì‹¤í–‰:**
```bash
./scripts/setup_master.sh
```

**GPU ì›Œì»¤ì—ì„œ ì‹¤í–‰:**
```bash
./scripts/setup_worker.sh
```

**ì›Œì»¤ê°€ ì¡°ì¸ëœ í›„, ë§ˆìŠ¤í„°ì—ì„œ ë¼ë²¨ë§:**
```bash
kubectl get nodes
kubectl label node <ì›Œì»¤ë…¸ë“œì´ë¦„> nvidia.com/gpu.present=true
```

### 3) ë°”ë¡œ ì‹¤í–‰
```bash
# ì¤€ë¹„ ìƒíƒœ ì ê²€
./scripts/preflight.sh

# ìŠ¤ëª¨í¬ í…ŒìŠ¤íŠ¸ (10ìƒ˜í”Œ, ~15ë¶„)
./scripts/run_benchmarks.sh --smoke

# ì „ì²´ ë²¤ì¹˜ë§ˆí¬ (8~10ì‹œê°„)
./scripts/run_benchmarks.sh
```

---

## ğŸ‘‡ ì´ ë ˆí¬ì—ì„œ ë³´ë©´ ë˜ëŠ” íŒŒì¼ë§Œ

```
config/cluster.env(.local)   # IP, ê³„ì •, HF í† í°
scripts/setup_master.sh      # ë§ˆìŠ¤í„° ì„¤ì¹˜
scripts/setup_worker.sh      # ì›Œì»¤ ì„¤ì¹˜
scripts/preflight.sh         # ì ê²€/ìë™ìˆ˜ì •
scripts/run_benchmarks.sh    # ì‹¤í–‰
k8s/jobs/*.yaml              # ì‹¤ì œ ì‹¤í–‰ë˜ëŠ” K8s Job
```

---

## ìì£¼ ì“°ëŠ” ëª…ë ¹ì–´

```bash
# íŠ¹ì • ë²¤ì¹˜ë§ˆí¬ë§Œ ì‹¤í–‰
./scripts/run_benchmarks.sh --smoke --mlperf
./scripts/run_benchmarks.sh --smoke --mmlu
./scripts/run_benchmarks.sh --smoke --inference

# ìë™ìˆ˜ì •(ë§ˆìŠ¤í„° IP ë³€ê²½, ë¼ë²¨ ëˆ„ë½ ë“±)
./scripts/preflight.sh --fix
./scripts/run_benchmarks.sh --smoke --fix
```

---

## ê²°ê³¼ ìœ„ì¹˜

```
results/<RUN_ID>/
â”œâ”€â”€ summary.txt
â”œâ”€â”€ mlperf-bench.log
â”œâ”€â”€ mlperf-bench-metrics.txt
â”œâ”€â”€ mmlu-bench.log
â””â”€â”€ inference-bench.log
```

---

## ê°„ë‹¨ íŠ¸ëŸ¬ë¸”ìŠˆíŒ…

### 1) í´ëŸ¬ìŠ¤í„° ì—°ê²° ì•ˆ ë¨
```bash
./scripts/preflight.sh --fix
sudo systemctl status kubelet
sudo crictl ps | grep kube-apiserver
```

### 2) GPU Pending
```bash
kubectl get nodes -o jsonpath='{.items[*].status.allocatable.nvidia\.com/gpu}'
kubectl logs -n kube-system -l name=nvidia-device-plugin-ds --tail=50
```

---

## ì°¸ê³ 
- `mlcommons_inference/` : MLCommons ê³µì‹ êµ¬í˜„(ì„œë¸Œëª¨ë“ˆ)
- `mmlu_pro/` : TIGER-Lab ê³µì‹ êµ¬í˜„(ì„œë¸Œëª¨ë“ˆ)
