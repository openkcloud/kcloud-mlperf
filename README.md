## kcloud-mlperf â€” ì¿ ë²„ë„¤í‹°ìŠ¤ LLM ë²¤ì¹˜ë§ˆí¬ (Llama 3.1 8B)

**ë§ˆìŠ¤í„°/ì›Œì»¤ IPë§Œ ì„¤ì •í•˜ë©´ ë°”ë¡œ ì‹¤í–‰ë˜ëŠ”** bare-metal K8s ë²¤ì¹˜ë§ˆí¬ ëª¨ìŒì…ë‹ˆë‹¤.

| ë²¤ì¹˜ë§ˆí¬ | ì„¤ëª… | êµ¬í˜„ |
|---|---|---|
| **MLPerf Inference** | CNN/DailyMail ìš”ì•½ â†’ ROUGE | **MLCommons ê³µì‹ LoadGen** |
| **MMLU-Pro** | 5-shot CoT í‰ê°€ â†’ ì •í™•ë„ | TIGER-Lab ê³µì‹ |
| **LLM Inference** | vLLM ì²˜ë¦¬ëŸ‰ í…ŒìŠ¤íŠ¸ | vLLM ë°±ì—”ë“œ |

> **ê¶Œì¥:** í•­ìƒ `--smoke`(10ìƒ˜í”Œ) ë¨¼ì € í†µê³¼ â†’ í’€ ë°ì´í„° ì‹¤í–‰

---

## âœ… ì²˜ìŒ ì‚¬ìš©ì ê°€ì´ë“œ (Bare Metal ì‹ ê·œ ì„œë²„ ì„¤ì •)

### 0) ì¤€ë¹„ë¬¼ ë° ì‹œìŠ¤í…œ ìš”êµ¬ì‚¬í•­

**í•˜ë“œì›¨ì–´:**
- Ubuntu 20.04/22.04 ë¨¸ì‹  2ëŒ€ ì´ìƒ (ë§ˆìŠ¤í„° 1 + GPU ì›Œì»¤ 1+)
- ì›Œì»¤ ë…¸ë“œ: NVIDIA GPU (ìµœì†Œ 16GB VRAM ê¶Œì¥)
- ë§ˆìŠ¤í„° ë…¸ë“œ: ìµœì†Œ 2GB RAM, 2 CPU ì½”ì–´
- ë„¤íŠ¸ì›Œí¬: ë§ˆìŠ¤í„°ì™€ ì›Œì»¤ ê°„ SSH ì ‘ê·¼ ê°€ëŠ¥

**ì†Œí”„íŠ¸ì›¨ì–´:**
- ì›Œì»¤ ë…¸ë“œì— NVIDIA ë“œë¼ì´ë²„ ì„¤ì¹˜ (ë²„ì „ 525 ì´ìƒ ê¶Œì¥)
- HuggingFace í† í° (Llama 3.1 ë¼ì´ì„ ìŠ¤ ìŠ¹ì¸ í•„ìš”)
  - í† í° ë°œê¸‰: https://huggingface.co/settings/tokens
- sudo ê¶Œí•œì´ ìˆëŠ” ì‚¬ìš©ì ê³„ì •

**NVIDIA ë“œë¼ì´ë²„ ì„¤ì¹˜ (ì›Œì»¤ ë…¸ë“œ):**
```bash
# Ubuntuì—ì„œ NVIDIA ë“œë¼ì´ë²„ ì„¤ì¹˜
sudo apt update
sudo apt install -y nvidia-driver-550  # ë˜ëŠ” ìµœì‹  ë²„ì „
sudo reboot

# ì„¤ì¹˜ í™•ì¸
nvidia-smi
```

### 1) ë ˆí¬ ë°›ê¸° ë° ì„¤ì • íŒŒì¼ ì‘ì„±

**ëª¨ë“  ë…¸ë“œì—ì„œ ì‹¤í–‰:**
```bash
git clone --recursive https://github.com/openkcloud/kcloud-mlperf.git
cd kcloud-mlperf
```

**ë§ˆìŠ¤í„° ë…¸ë“œì—ì„œ ì„¤ì • íŒŒì¼ ì‘ì„±:**
```bash
cp config/cluster.env config/cluster.env.local
nano config/cluster.env.local
```

`config/cluster.env.local` ì˜ˆì‹œ:
```bash
# Master Node Configuration
MASTER_IP="192.168.1.100"          # ë§ˆìŠ¤í„° ë…¸ë“œ IP (ì‹¤ì œ IPë¡œ ë³€ê²½)
MASTER_USER="ubuntu"               # ë§ˆìŠ¤í„° ë…¸ë“œ ì‚¬ìš©ìëª… (ì‹¤ì œ ì‚¬ìš©ìëª…ìœ¼ë¡œ ë³€ê²½)

# Worker Node Configuration
WORKER_IP="192.168.1.101"          # ì›Œì»¤ ë…¸ë“œ IP (ì‹¤ì œ IPë¡œ ë³€ê²½)
WORKER_USER="ubuntu"               # ì›Œì»¤ ë…¸ë“œ ì‚¬ìš©ìëª… (ì‹¤ì œ ì‚¬ìš©ìëª…ìœ¼ë¡œ ë³€ê²½)
WORKER_SSH_PORT="22"               # SSH í¬íŠ¸ (ê¸°ë³¸ê°’: 22)

# HuggingFace Token (í•„ìˆ˜)
HF_TOKEN="hf_xxxxxxxxxxxxxxxxxxxx"  # HuggingFace í† í° (ì‹¤ì œ í† í°ìœ¼ë¡œ ë³€ê²½)

# Kubernetes Configuration (ì„ íƒì‚¬í•­)
K8S_VERSION="1.28"                 # Kubernetes ë²„ì „
POD_NETWORK_CIDR="10.244.0.0/16"  # Pod ë„¤íŠ¸ì›Œí¬ CIDR
```

**ì›Œì»¤ ë…¸ë“œì—ì„œ ì„¤ì • íŒŒì¼ ì‘ì„± (ìµœì†Œí•œ MASTER_IP í•„ìš”):**
```bash
# ì›Œì»¤ ë…¸ë“œì—ì„œë„ ë ˆí¬ë¥¼ ë°›ì€ í›„
cp config/cluster.env config/cluster.env.local
nano config/cluster.env.local
```

ì›Œì»¤ ë…¸ë“œ ìµœì†Œ ì„¤ì •:
```bash
MASTER_IP="192.168.1.100"          # ë§ˆìŠ¤í„° ë…¸ë“œ IP (ì‹¤ì œ IPë¡œ ë³€ê²½, í•„ìˆ˜)
MASTER_USER="ubuntu"               # ë§ˆìŠ¤í„° ë…¸ë“œ ì‚¬ìš©ìëª… (ì‹¤ì œ ì‚¬ìš©ìëª…ìœ¼ë¡œ ë³€ê²½, í•„ìˆ˜)
HF_TOKEN="hf_xxxxxxxxxxxxxxxxxxxx"  # HuggingFace í† í° (ì‹¤ì œ í† í°ìœ¼ë¡œ ë³€ê²½)
```

### 2) í´ëŸ¬ìŠ¤í„° ì„¤ì¹˜

#### 2-1) ë§ˆìŠ¤í„° ë…¸ë“œ ì„¤ì •

**ë§ˆìŠ¤í„° ë…¸ë“œì—ì„œ ì‹¤í–‰:**
```bash
cd ~/kcloud-mlperf
./scripts/setup_master.sh
```

ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ” ìë™ìœ¼ë¡œ:
- ì‹œìŠ¤í…œ ì¤€ë¹„ (swap ë¹„í™œì„±í™”, ì»¤ë„ ëª¨ë“ˆ ë¡œë“œ)
- containerd ì„¤ì¹˜ ë° ì„¤ì •
- Kubernetes (kubeadm, kubelet, kubectl) ì„¤ì¹˜
- í´ëŸ¬ìŠ¤í„° ì´ˆê¸°í™” (`kubeadm init`)
- CNI í”ŒëŸ¬ê·¸ì¸ (Flannel) ì„¤ì¹˜
- NVIDIA RuntimeClass ìƒì„±
- NVIDIA Device Plugin ì„¤ì¹˜
- ì›Œì»¤ ì¡°ì¸ ëª…ë ¹ì–´ ìƒì„± (`config/join-command.sh`)

**ì„¤ì¹˜ ì™„ë£Œ í›„ í™•ì¸:**
```bash
kubectl get nodes
kubectl get pods -n kube-system
```

#### 2-2) ì›Œì»¤ ë…¸ë“œ ì„¤ì •

**ì›Œì»¤ ë…¸ë“œì—ì„œ ì‹¤í–‰:**
```bash
cd ~/kcloud-mlperf
git pull  # ìµœì‹  ì½”ë“œ ë°›ê¸°

# ìë™ ì¡°ì¸ ëª¨ë“œ (ê¶Œì¥)
./scripts/setup_worker.sh --auto-join
```

ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ” ìë™ìœ¼ë¡œ:
- ì‹œìŠ¤í…œ ì¤€ë¹„ (swap ë¹„í™œì„±í™”, ì»¤ë„ ëª¨ë“ˆ ë¡œë“œ)
- containerd ì„¤ì¹˜ ë° ì„¤ì •
- NVIDIA Container Toolkit ì„¤ì¹˜ ë° ì„¤ì •
- Kubernetes (kubeadm, kubelet, kubectl) ì„¤ì¹˜
- SSH í‚¤ ìë™ ìƒì„± ë° ë§ˆìŠ¤í„°ì— ë³µì‚¬ (ë¹„ë°€ë²ˆí˜¸ 1íšŒ ì…ë ¥)
- ë§ˆìŠ¤í„°ì—ì„œ ì¡°ì¸ ëª…ë ¹ì–´ ìë™ ê°€ì ¸ì˜¤ê¸°
- í´ëŸ¬ìŠ¤í„° ìë™ ì¡°ì¸ (`kubeadm join`)
- ë¶ˆì™„ì „í•œ ì¡°ì¸ ìƒíƒœ ìë™ ì •ë¦¬

**ìˆ˜ë™ ëª¨ë“œ (ìë™ ì¡°ì¸ì´ ì‹¤íŒ¨í•œ ê²½ìš°):**
```bash
./scripts/setup_worker.sh
# ì¡°ì¸ ëª…ë ¹ì–´ë¥¼ ìˆ˜ë™ìœ¼ë¡œ ì…ë ¥í•˜ê±°ë‚˜
# ë§ˆìŠ¤í„°ì—ì„œ ìƒì„±ëœ join-command.shë¥¼ ë³µì‚¬í•˜ì—¬ ì‹¤í–‰
```

**ì›Œì»¤ ì¡°ì¸ í™•ì¸ (ë§ˆìŠ¤í„° ë…¸ë“œì—ì„œ):**
```bash
kubectl get nodes
# ì›Œì»¤ ë…¸ë“œê°€ Ready ìƒíƒœê°€ ë  ë•Œê¹Œì§€ ëŒ€ê¸° (ë³´í†µ 1-2ë¶„)
```

#### 2-3) ì›Œì»¤ ë…¸ë“œ ë¼ë²¨ë§ (GPU ìŠ¤ì¼€ì¤„ë§ìš©)

**ë§ˆìŠ¤í„° ë…¸ë“œì—ì„œ ì‹¤í–‰:**
```bash
# ì›Œì»¤ ë…¸ë“œ ì´ë¦„ í™•ì¸
kubectl get nodes

# GPU ì›Œì»¤ ë…¸ë“œì— ë¼ë²¨ ì¶”ê°€
kubectl label node <ì›Œì»¤ë…¸ë“œì´ë¦„> nvidia.com/gpu.present=true

# ë¼ë²¨ í™•ì¸
kubectl get nodes --show-labels
```

### 3) í´ëŸ¬ìŠ¤í„° ê²€ì¦ ë° ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰

**ì¤€ë¹„ ìƒíƒœ ì ê²€:**
```bash
# ë§ˆìŠ¤í„° ë…¸ë“œì—ì„œ ì‹¤í–‰
./scripts/preflight.sh
```

ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ” ë‹¤ìŒì„ í™•ì¸í•©ë‹ˆë‹¤:
- í´ëŸ¬ìŠ¤í„° ì—°ê²° ìƒíƒœ
- GPU í• ë‹¹ ê°€ëŠ¥ ì—¬ë¶€ (NVIDIA Device Plugin)
- ë…¸ë“œ ë¼ë²¨ ì„¤ì •
- HuggingFace í† í° ì„¤ì •

**ìŠ¤ëª¨í¬ í…ŒìŠ¤íŠ¸ (10ìƒ˜í”Œ, ~15ë¶„):**
```bash
./scripts/run_benchmarks.sh --smoke
```

**ì „ì²´ ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰ (8~10ì‹œê°„):**
```bash
./scripts/run_benchmarks.sh
```

**íŠ¹ì • ë²¤ì¹˜ë§ˆí¬ë§Œ ì‹¤í–‰:**
```bash
./scripts/run_benchmarks.sh --smoke --mlperf    # MLPerf Inferenceë§Œ
./scripts/run_benchmarks.sh --smoke --mmlu       # MMLU-Proë§Œ
./scripts/run_benchmarks.sh --smoke --inference  # LLM Inferenceë§Œ
```

---

## ğŸ“ ì£¼ìš” íŒŒì¼ êµ¬ì¡°

```
kcloud-mlperf/
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ cluster.env              # ì„¤ì • í…œí”Œë¦¿
â”‚   â””â”€â”€ cluster.env.local        # ì‹¤ì œ ì„¤ì • (gitignored)
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ setup_master.sh          # ë§ˆìŠ¤í„° ë…¸ë“œ ìë™ ì„¤ì •
â”‚   â”œâ”€â”€ setup_worker.sh          # ì›Œì»¤ ë…¸ë“œ ìë™ ì„¤ì • (--auto-join ì§€ì›)
â”‚   â”œâ”€â”€ preflight.sh             # í´ëŸ¬ìŠ¤í„° ìƒíƒœ ì ê²€/ìë™ìˆ˜ì •
â”‚   â””â”€â”€ run_benchmarks.sh        # ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰
â”œâ”€â”€ k8s/
â”‚   â””â”€â”€ jobs/
â”‚       â”œâ”€â”€ mlperf-job.yaml      # MLPerf Inference Job
â”‚       â”œâ”€â”€ mmlu-job.yaml        # MMLU-Pro Job
â”‚       â””â”€â”€ inference-job.yaml   # LLM Inference Job
â””â”€â”€ results/                     # ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼ ì €ì¥
```

## ğŸš€ ìë™í™” ê¸°ëŠ¥

### setup_master.sh
- âœ… ë¶ˆì™„ì „í•œ kubeadm ìƒíƒœ ìë™ ê°ì§€ ë° ì •ë¦¬
- âœ… Flannel CNI ìë™ ì„¤ì¹˜
- âœ… NVIDIA Device Plugin ìë™ ì„¤ì¹˜
- âœ… ì›Œì»¤ ì¡°ì¸ ëª…ë ¹ì–´ ìë™ ìƒì„±

### setup_worker.sh
- âœ… ë¶ˆì™„ì „í•œ ì¡°ì¸ ìƒíƒœ ìë™ ê°ì§€ ë° ì •ë¦¬
- âœ… SSH í‚¤ ìë™ ìƒì„± ë° ë§ˆìŠ¤í„°ì— ë³µì‚¬ (ë¹„ë°€ë²ˆí˜¸ 1íšŒ ì…ë ¥)
- âœ… ë§ˆìŠ¤í„°ì—ì„œ ì¡°ì¸ ëª…ë ¹ì–´ ìë™ ê°€ì ¸ì˜¤ê¸°
- âœ… `--auto-join` í”Œë˜ê·¸ë¡œ ì™„ì „ ìë™í™”
- âœ… containerd ìë™ ì¬ì‹œì‘ (í•„ìš” ì‹œ)

---

## ìì£¼ ì“°ëŠ” ëª…ë ¹ì–´

```bash
# íŠ¹ì • ë²¤ì¹˜ë§ˆí¬ë§Œ ì‹¤í–‰
./scripts/run_benchmarks.sh --smoke --mlperf
./scripts/run_benchmarks.sh --smoke --mmlu
./scripts/run_benchmarks.sh --smoke --inference

# ìë™ìˆ˜ì •(ë§ˆìŠ¤í„° IP ë³€ê²½, ë¼ë²¨ ëˆ„ë½ ë“±)
./scripts/preflight.sh --fix
./scripts/run_benchmarks.sh --smoke --fix
```

---

## ê²°ê³¼ ìœ„ì¹˜

```
results/<RUN_ID>/
â”œâ”€â”€ summary.txt
â”œâ”€â”€ mlperf-bench.log
â”œâ”€â”€ mlperf-bench-metrics.txt
â”œâ”€â”€ mmlu-bench.log
â””â”€â”€ inference-bench.log
```

---

## ğŸ”§ íŠ¸ëŸ¬ë¸”ìŠˆíŒ…

### 1) í´ëŸ¬ìŠ¤í„° ì—°ê²° ì•ˆ ë¨

**ì¦ìƒ:** `kubectl get nodes` ì‹¤í–‰ ì‹œ ì—°ê²° ì˜¤ë¥˜

**í•´ê²°:**
```bash
# ìë™ ìˆ˜ì • ì‹œë„
./scripts/preflight.sh --fix

# ìˆ˜ë™ í™•ì¸
sudo systemctl status kubelet
sudo systemctl status containerd
sudo crictl ps | grep kube-apiserver

# kubeconfig í™•ì¸
ls -la ~/.kube/config
```

### 2) ì›Œì»¤ ë…¸ë“œê°€ ì¡°ì¸ë˜ì§€ ì•ŠìŒ

**ì¦ìƒ:** `kubectl get nodes`ì—ì„œ ì›Œì»¤ ë…¸ë“œê°€ ë³´ì´ì§€ ì•ŠìŒ

**í•´ê²°:**
```bash
# ì›Œì»¤ ë…¸ë“œì—ì„œ
./scripts/setup_worker.sh --auto-join

# ë˜ëŠ” ìˆ˜ë™ìœ¼ë¡œ ì •ë¦¬ í›„ ì¬ì¡°ì¸
sudo kubeadm reset --force
sudo rm -rf /etc/kubernetes/pki
sudo rm -rf /etc/cni/net.d/*
sudo systemctl restart containerd
./scripts/setup_worker.sh --auto-join
```

### 3) GPU Pending ë˜ëŠ” Insufficient nvidia.com/gpu

**ì¦ìƒ:** Podê°€ Pending ìƒíƒœì´ê³  `Insufficient nvidia.com/gpu` ì˜¤ë¥˜

**í•´ê²°:**
```bash
# GPU í• ë‹¹ ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸
kubectl get nodes -o jsonpath='{.items[*].status.allocatable.nvidia\.com/gpu}'

# NVIDIA Device Plugin ìƒíƒœ í™•ì¸
kubectl get pods -n kube-system -l name=nvidia-device-plugin-ds
kubectl logs -n kube-system -l name=nvidia-device-plugin-ds --tail=50

# Device Plugin ì¬ì‹œì‘
kubectl delete pod -n kube-system -l name=nvidia-device-plugin-ds

# ë…¸ë“œ ë¼ë²¨ í™•ì¸
kubectl get nodes --show-labels | grep nvidia.com/gpu.present
```

### 4) SSH ì—°ê²° ì‹¤íŒ¨ (ì›Œì»¤ â†’ ë§ˆìŠ¤í„°)

**ì¦ìƒ:** ì›Œì»¤ ë…¸ë“œì—ì„œ ë§ˆìŠ¤í„°ë¡œ SSH ì—°ê²° ì‹¤íŒ¨

**í•´ê²°:**
```bash
# ì›Œì»¤ ë…¸ë“œì—ì„œ
# 1. SSH í‚¤ í™•ì¸
ls -la ~/.ssh/id_ed25519_kcloud*

# 2. ìˆ˜ë™ìœ¼ë¡œ SSH í‚¤ ë³µì‚¬
ssh-copy-id -i ~/.ssh/id_ed25519_kcloud.pub <MASTER_USER>@<MASTER_IP>

# 3. ë˜ëŠ” setup_worker.shê°€ ìë™ìœ¼ë¡œ ì²˜ë¦¬ (ë¹„ë°€ë²ˆí˜¸ 1íšŒ ì…ë ¥)
./scripts/setup_worker.sh --auto-join
```

### 4b) GPU ë©”ëª¨ë¦¬ ë¶€ì¡± ë˜ëŠ” ì›Œì»¤ ë…¸ë“œ ë¬¸ì œ

**ì¦ìƒ:** GPUê°€ ì‚¬ìš© ì¤‘ì´ê±°ë‚˜ ì›Œì»¤ ë…¸ë“œê°€ NotReady ìƒíƒœ

**í•´ê²°:**
```bash
# ì›Œì»¤ ë…¸ë“œì—ì„œ - setup_worker.shê°€ ìë™ìœ¼ë¡œ ì²˜ë¦¬í•©ë‹ˆë‹¤
./scripts/setup_worker.sh --auto-join --free-gpu

# ë˜ëŠ” GPUë§Œ í•´ì œí•˜ë ¤ë©´ (ìë™ ê°ì§€ë¨)
./scripts/setup_worker.sh --free-gpu

# setup_worker.shëŠ” ë‹¤ìŒì„ ìë™ìœ¼ë¡œ ì²˜ë¦¬í•©ë‹ˆë‹¤:
# - GPU ì‚¬ìš© í”„ë¡œì„¸ìŠ¤ ìë™ ê°ì§€ ë° ì¢…ë£Œ
# - Calico CNI ì¶©ëŒ ìë™ ì •ë¦¬
# - kubelet ì¬ì‹œì‘ (í•„ìš” ì‹œ)
```

### 5) containerd ì˜¤ë¥˜: "container runtime is not running"

**ì¦ìƒ:** `kubeadm join` ì‹¤í–‰ ì‹œ containerd ì—°ê²° ì˜¤ë¥˜

**í•´ê²°:**
```bash
# containerd ìƒíƒœ í™•ì¸
sudo systemctl status containerd

# containerd ì¬ì‹œì‘
sudo systemctl restart containerd
sudo systemctl enable containerd

# í™•ì¸
sudo crictl ps
```

### 6) ë¶ˆì™„ì „í•œ kubeadm ìƒíƒœ ì˜¤ë¥˜

**ì¦ìƒ:** `kubeadm init` ë˜ëŠ” `kubeadm join` ì‹¤í–‰ ì‹œ "file already exists" ì˜¤ë¥˜

**í•´ê²°:**
```bash
# ë§ˆìŠ¤í„° ë…¸ë“œì—ì„œ
sudo kubeadm reset --force
sudo rm -rf /etc/kubernetes/pki
sudo rm -rf /etc/kubernetes/manifests
sudo rm -f /etc/kubernetes/*.conf
sudo rm -rf /etc/cni/net.d/*
sudo systemctl restart containerd
./scripts/setup_master.sh

# ì›Œì»¤ ë…¸ë“œì—ì„œ
sudo kubeadm reset --force
sudo rm -rf /etc/kubernetes/pki
sudo rm -rf /etc/cni/net.d/*
sudo systemctl restart containerd
./scripts/setup_worker.sh --auto-join
```

### 7) Calico CNI ì¶©ëŒ

**ì¦ìƒ:** Flannelê³¼ Calicoê°€ ë™ì‹œì— ì„¤ì¹˜ë˜ì–´ ì¶©ëŒ

**í•´ê²°:**
```bash
# ë§ˆìŠ¤í„° ë…¸ë“œì—ì„œ
sudo rm -f /etc/cni/net.d/10-calico.conflist
sudo rm -f /etc/cni/net.d/calico-kubeconfig
sudo systemctl restart kubelet
# setup_master.shê°€ ìë™ìœ¼ë¡œ ì²˜ë¦¬í•©ë‹ˆë‹¤
```

---

## ì°¸ê³ 
- `mlcommons_inference/` : MLCommons ê³µì‹ êµ¬í˜„(ì„œë¸Œëª¨ë“ˆ)
- `mmlu_pro/` : TIGER-Lab ê³µì‹ êµ¬í˜„(ì„œë¸Œëª¨ë“ˆ)
